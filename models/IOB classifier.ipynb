{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn_crfsuite import metrics as crf_metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "import gensim\n",
    "import json \n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\RAYMOND\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\RAYMOND\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# !pip install sklearn-crfsuite -U\n",
    "# !pip install -U 'scikit-learn<0.24'\n",
    "# !pip install gensim"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T10:34:01.740395Z",
     "start_time": "2024-10-17T10:34:00.966377Z"
    }
   },
   "source": [
    "train_df = pd.concat([pd.read_csv(file, sep='\\t') for file in glob.glob('../data/train/*-tokens.tsv')])\n",
    "train_df.sort_values('document_ID', inplace=True)\n",
    "train_df.to_csv('../data/train-full.tsv', index=False, sep='\\t')"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T10:34:03.448506Z",
     "start_time": "2024-10-17T10:34:03.300962Z"
    }
   },
   "source": [
    "train_df = pd.read_csv('../data/train-full.tsv', sep='\\t')\n",
    "validation_df = pd.read_csv('../data/validation-full.tsv', sep='\\t')"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T10:34:05.733827Z",
     "start_time": "2024-10-17T10:34:04.011421Z"
    }
   },
   "source": [
    "train_df['doc-sent'] = [str(row.document_ID) + '-' + str(row.sentence_ID) for index, row in train_df.iterrows()]\n",
    "validation_df['doc-sent'] = [str(row.document_ID) + '-' + str(row.sentence_ID) for index, row in validation_df.iterrows()]"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratio transformations"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T10:34:05.749452Z",
     "start_time": "2024-10-17T10:34:05.738341Z"
    }
   },
   "source": [
    "# Make new columns\n",
    "train_df['total_occurences'] = 0\n",
    "train_df['class_occurences'] = 0\n",
    "train_df['attribute_occurences'] = 0\n",
    "validation_df['total_occurences'] = 0\n",
    "validation_df['class_occurences'] = 0\n",
    "validation_df['attribute_occurences'] = 0"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T10:34:07.197636Z",
     "start_time": "2024-10-17T10:34:06.484212Z"
    }
   },
   "source": [
    "with open('../data/genmymodel/genmymodel_uml_extracted_metadata_final.json') as json_file:\n",
    "    gmm_data = json.load(json_file)\n",
    "\n",
    "# Store all classes and attributes independent of eachother\n",
    "all_classes = []\n",
    "all_attrs = []\n",
    "\n",
    "# Loop over all metadata and append to proper list\n",
    "for file, metadata in gmm_data.items():\n",
    "    if 'classes' in metadata.keys():\n",
    "        all_classes.append(metadata['classes'])\n",
    "\n",
    "    if 'attributes' in metadata.keys():\n",
    "        all_attrs.append(metadata['attributes'])\n",
    "\n",
    "flatten = lambda t: [item for sublist in t for item in sublist]\n",
    "\n",
    "all_classes = flatten(all_classes)\n",
    "all_attrs = flatten(all_attrs)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T10:34:26.853484Z",
     "start_time": "2024-10-17T10:34:07.308370Z"
    }
   },
   "source": [
    "noungroup = []\n",
    "noungroup_indices = []\n",
    "\n",
    "for index, row in tqdm(validation_df.iterrows()):\n",
    "    if isinstance(row['fine_POS_tag'], str) and row['fine_POS_tag'][:2] == 'NN':\n",
    "        noungroup.append(row['word'])\n",
    "        noungroup_indices.append(index)\n",
    "    else:\n",
    "        if len(noungroup) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            full_ng = ' '.join(noungroup).lower()\n",
    "            attr_no = all_attrs.count(full_ng)\n",
    "            class_no = all_classes.count(full_ng)\n",
    "            \n",
    "            for noun_index in noungroup_indices:\n",
    "                validation_df.loc[noun_index, ['class_occurences', 'attribute_occurences', 'total_occurences']] = [class_no, attr_no, attr_no + class_no]\n",
    "                \n",
    "            noungroup = []\n",
    "            noungroup_indices = []"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "73a8d5ebc3584e1ca73c7bc63675aa2a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare IOB format"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T10:34:26.914783Z",
     "start_time": "2024-10-17T10:34:26.882047Z"
    }
   },
   "source": [
    "columns = ['doc-sent', 'word', 'lemma', 'POS_tag', 'fine_POS_tag', 'dependency_relation', 'event', 'supersense_category', 'entity', 'entity_type', 'entity_category', 'total_occurences', 'class_occurences', 'attribute_occurences', 'IOB_tag']\n",
    "train_df = train_df[columns]\n",
    "validation_df = validation_df[columns]"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T10:34:26.992591Z",
     "start_time": "2024-10-17T10:34:26.978419Z"
    }
   },
   "source": [
    "agg_func = lambda s: list(map(lambda w: tuple(w), s.loc[:, s.columns != 'doc-sent'].values.tolist()))"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T10:34:27.744325Z",
     "start_time": "2024-10-17T10:34:27.055431Z"
    }
   },
   "source": [
    "train_grouped_df = train_df.groupby('doc-sent').apply(agg_func)\n",
    "validation_grouped_df = validation_df.groupby('doc-sent').apply(agg_func)\n",
    "\n",
    "train_sentences = [s for s in train_grouped_df]\n",
    "validation_sentences = [s for s in validation_grouped_df]"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-10-17T10:34:27.839073Z",
     "start_time": "2024-10-17T10:34:27.808843Z"
    }
   },
   "source": [
    "train_grouped_df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "doc-sent\n",
       "0-0      [(Software, Software, PROPN, NNP, compound, O,...\n",
       "0-1      [(of, of, ADP, IN, prep, O, nan, nan, nan, nan...\n",
       "0-10     [(., ., PUNCT, ., punct, O, nan, nan, nan, nan...\n",
       "0-100    [(metadata, metadata, NOUN, NN, nsubjpass, O, ...\n",
       "0-101    [(., ., PUNCT, ., punct, O, nan, nan, nan, nan...\n",
       "                               ...                        \n",
       "9-95     [(to, to, PART, TO, aux, O, nan, nan, nan, nan...\n",
       "9-96     [(The, the, DET, DT, det, O, nan, nan, nan, na...\n",
       "9-97     [(The, the, DET, DT, det, O, nan, nan, nan, na...\n",
       "9-98     [(against, against, ADP, IN, prep, O, nan, nan...\n",
       "9-99     [(The, the, DET, DT, det, O, nan, nan, nan, na...\n",
       "Length: 3130, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T10:34:27.930732Z",
     "start_time": "2024-10-17T10:34:27.900116Z"
    }
   },
   "source": [
    "train_df.dropna(subset=['doc-sent'], inplace=True)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T10:34:28.976447Z",
     "start_time": "2024-10-17T10:34:27.933715Z"
    }
   },
   "source": [
    "# fastText model for embedding generation\n",
    "vocab = train_df['word'].values.tolist() + validation_df['word'].values.tolist()\n",
    "model = gensim.models.FastText(vocab, min_count=1)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-10-17T10:34:29.712923Z"
    }
   },
   "source": [
    "pickle.dump(model, open('fasttext-model.pkl', 'wb'))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def word2features(sent, i, embedding, ratio):\n",
    "    word = sent[i][1]\n",
    "    postag = sent[i][3]\n",
    "    fine_postag = sent[i][4]\n",
    "    \n",
    "    features = {\n",
    "        label: data\n",
    "        for label, data in zip(columns[1:-1], sent[i][:-1])\n",
    "    }\n",
    "    \n",
    "    features.update({\n",
    "        'word.lower()': word.lower(),\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'postag[:2]': postag[:2],\n",
    "        'postag[:2]': postag[:2],\n",
    "        'finepostag[:2]': fine_postag[:2],\n",
    "        'finepostag[:2]': fine_postag[:2],\n",
    "    })\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][1]\n",
    "        postag1 = sent[i-1][3]\n",
    "        finepostag1 = sent[i-1][4]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "            '-1:finepostag': finepostag1,\n",
    "            '-1:finepostag[:2]': finepostag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][1]\n",
    "        postag1 = sent[i+1][3]\n",
    "        finepostag1 = sent[i-1][4]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "            '+1:finepostag': finepostag1,\n",
    "            '+1:finepostag[:2]': finepostag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "    \n",
    "    if not ratio:\n",
    "        for ratio_feature in ['total_occurences', 'class_occurences', 'attribute_occurences']:\n",
    "            del features[ratio_feature]\n",
    "        \n",
    "    if embedding:\n",
    "        word_embedding = model.wv.get_vector(word)\n",
    "        \n",
    "        features.update({\n",
    "            f'emb_pos_{i}': word_embedding[i]\n",
    "            for i in range(len(word_embedding))\n",
    "        })\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent, embedding = False, ratio = False):\n",
    "    return [word2features(sent, i, embedding, ratio) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return list(map(lambda s: s[-1], sent))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "sent2features(validation_sentences[0][:7])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "X_train = np.array([sent2features(s) for s in train_sentences])\n",
    "X_test = np.array([sent2features(s) for s in validation_sentences])\n",
    "y_train = np.array([sent2labels(s) for s in train_sentences])\n",
    "y_test = np.array([sent2labels(s) for s in validation_sentences])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "labels = list(train_df['IOB_tag'].unique())\n",
    "labels.remove('O')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "crf = CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.05),\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# use the same metric for evaluation\n",
    "f1_scorer = make_scorer(crf_metrics.flat_f1_score, average='weighted', labels=labels)\n",
    "\n",
    "# search\n",
    "rs = RandomizedSearchCV(crf, params_space,\n",
    "                        cv=3,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        n_iter=50,\n",
    "                        scoring=f1_scorer)\n",
    "rs.fit(X_train, y_train)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "y_pred = rs.predict(X_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "labels"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(crf_metrics.flat_classification_report(y_test, y_pred, labels=labels, digits=3))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "[[[word['word'], pred] for word, pred in zip(sent, predictions)] for sent, predictions in zip(X_test, y_pred)]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default model + fastText"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "X_train = np.array([sent2features(s, embedding = True) for s in train_sentences])\n",
    "X_test = np.array([sent2features(s, embedding = True) for s in validation_sentences])\n",
    "y_train = np.array([sent2labels(s) for s in train_sentences])\n",
    "y_test = np.array([sent2labels(s) for s in validation_sentences])\n",
    "\n",
    "crf = CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "\n",
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.05),\n",
    "}\n",
    "\n",
    "# use the same metric for evaluation\n",
    "f1_scorer = make_scorer(crf_metrics.flat_f1_score, average='weighted', labels=labels)\n",
    "\n",
    "# search\n",
    "rs = RandomizedSearchCV(crf, params_space,\n",
    "                        cv=3,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        n_iter=50,\n",
    "                        scoring=f1_scorer)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "rs.fit(X_train, y_train)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "y_pred = rs.predict(X_test)\n",
    "print(crf_metrics.flat_classification_report(y_test, y_pred, labels=labels, digits=3))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default model + class/attribute ratio"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "X_train = np.array([sent2features(s, ratio = True) for s in train_sentences])\n",
    "X_test = np.array([sent2features(s, ratio = True) for s in validation_sentences])\n",
    "y_train = np.array([sent2labels(s) for s in train_sentences])\n",
    "y_test = np.array([sent2labels(s) for s in validation_sentences])\n",
    "\n",
    "crf = CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "\n",
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.05),\n",
    "}\n",
    "\n",
    "# use the same metric for evaluation\n",
    "f1_scorer = make_scorer(crf_metrics.flat_f1_score, average='weighted', labels=labels)\n",
    "\n",
    "# search\n",
    "rs = RandomizedSearchCV(crf, params_space,\n",
    "                        cv=3,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        n_iter=50,\n",
    "                        scoring=f1_scorer)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "rs.fit(X_train, y_train)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "y_pred = rs.predict(X_test)\n",
    "print(crf_metrics.flat_classification_report(y_test, y_pred, labels=labels, digits=3))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All features together"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "X_train = np.array([sent2features(s, ratio = True, embedding = True) for s in train_sentences])\n",
    "X_test = np.array([sent2features(s, ratio = True, embedding = True) for s in validation_sentences])\n",
    "y_train = np.array([sent2labels(s) for s in train_sentences])\n",
    "y_test = np.array([sent2labels(s) for s in validation_sentences])\n",
    "\n",
    "crf = CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "\n",
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.05),\n",
    "}\n",
    "\n",
    "# use the same metric for evaluation\n",
    "f1_scorer = make_scorer(crf_metrics.flat_f1_score, average='weighted', labels=labels)\n",
    "\n",
    "# search\n",
    "rs = RandomizedSearchCV(crf, params_space,\n",
    "                        cv=3,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        n_iter=50,\n",
    "                        scoring=f1_scorer)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "rs.fit(X_train, y_train)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "y_pred = rs.predict(X_test)\n",
    "print(crf_metrics.flat_classification_report(y_test, y_pred, labels=labels, digits=3))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "pickle.dump(rs, open('model-new.pkl', 'wb'))",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
